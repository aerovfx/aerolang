#!/usr/bin/env python3
"""
üß™ MPS Compatibility Test
Test MPS compatibility v·ªõi Whisper models
"""

import os
import sys
import torch
import whisper
import time

def test_mps_basic():
    """Test MPS basic functionality"""
    print("üß™ Testing MPS basic functionality...")
    
    try:
        # Test MPS availability
        mps_available = torch.backends.mps.is_available()
        print(f"   MPS available: {mps_available}")
        
        if not mps_available:
            print("   ‚ùå MPS not available")
            return False
        
        # Test device creation
        device = torch.device("mps")
        print(f"   MPS device: {device}")
        
        # Test basic tensor operations
        test_tensor = torch.tensor([1, 2, 3], device=device)
        print(f"   ‚úÖ Basic tensor: {test_tensor}")
        
        # Test matrix operations
        matrix = torch.randn(3, 3, device=device)
        result = torch.mm(matrix, matrix)
        print(f"   ‚úÖ Matrix multiplication: {result.shape}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå MPS basic test failed: {e}")
        return False

def test_whisper_mps():
    """Test Whisper v·ªõi MPS"""
    print("\nüß™ Testing Whisper v·ªõi MPS...")
    
    try:
        # Load tiny model v·ªõi MPS
        print("   Loading tiny model v·ªõi MPS...")
        model = whisper.load_model("tiny", device="mps")
        print("   ‚úÖ Model loaded v·ªõi MPS")
        
        # Test model properties
        print(f"   Model device: {next(model.parameters()).device}")
        print(f"   Model dtype: {next(model.parameters()).dtype}")
        
        # Test transcribe v·ªõi dummy audio (n·∫øu c√≥)
        print("   Testing transcribe...")
        
        # T·∫°o dummy audio tensor
        dummy_audio = torch.randn(16000, device="mps")  # 1 second at 16kHz
        
        # Test transcribe
        result = model.transcribe(dummy_audio, fp16=False, verbose=False)
        print("   ‚úÖ Transcribe test successful")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Whisper MPS test failed: {e}")
        return False

def test_whisper_cpu_fallback():
    """Test Whisper v·ªõi CPU fallback"""
    print("\nüß™ Testing Whisper v·ªõi CPU fallback...")
    
    try:
        # Load tiny model v·ªõi CPU
        print("   Loading tiny model v·ªõi CPU...")
        model = whisper.load_model("tiny", device="cpu")
        print("   ‚úÖ Model loaded v·ªõi CPU")
        
        # Test transcribe
        dummy_audio = torch.randn(16000, device="cpu")
        result = model.transcribe(dummy_audio, fp16=False, verbose=False)
        print("   ‚úÖ CPU transcribe test successful")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Whisper CPU test failed: {e}")
        return False

def test_model_sizes():
    """Test c√°c model sizes kh√°c nhau"""
    print("\nüß™ Testing different model sizes...")
    
    model_sizes = ["tiny", "base", "small"]
    
    for size in model_sizes:
        print(f"   Testing {size} model...")
        try:
            # Test v·ªõi CPU tr∆∞·ªõc
            model = whisper.load_model(size, device="cpu")
            print(f"   ‚úÖ {size} model loaded v·ªõi CPU")
            
            # Test v·ªõi MPS n·∫øu c√≥ th·ªÉ
            try:
                model_mps = whisper.load_model(size, device="mps")
                print(f"   ‚úÖ {size} model loaded v·ªõi MPS")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  {size} model MPS failed: {e}")
                
        except Exception as e:
            print(f"   ‚ùå {size} model failed: {e}")

def benchmark_performance():
    """Benchmark performance"""
    print("\nüìä Performance benchmark...")
    
    # Test CPU performance
    print("   Testing CPU performance...")
    start_time = time.time()
    model_cpu = whisper.load_model("tiny", device="cpu")
    cpu_load_time = time.time() - start_time
    print(f"   CPU load time: {cpu_load_time:.2f}s")
    
    # Test MPS performance n·∫øu c√≥ th·ªÉ
    if torch.backends.mps.is_available():
        print("   Testing MPS performance...")
        start_time = time.time()
        try:
            model_mps = whisper.load_model("tiny", device="mps")
            mps_load_time = time.time() - start_time
            print(f"   MPS load time: {mps_load_time:.2f}s")
            
            if mps_load_time < cpu_load_time:
                print("   ‚úÖ MPS faster than CPU")
            else:
                print("   ‚ö†Ô∏è  CPU faster than MPS")
                
        except Exception as e:
            print(f"   ‚ùå MPS benchmark failed: {e}")

def main():
    """Main function"""
    print("üß™ MPS Compatibility Test Suite")
    print("=" * 50)
    
    # Test 1: Basic MPS
    mps_basic = test_mps_basic()
    
    # Test 2: Whisper MPS
    whisper_mps = False
    if mps_basic:
        whisper_mps = test_whisper_mps()
    
    # Test 3: Whisper CPU
    whisper_cpu = test_whisper_cpu_fallback()
    
    # Test 4: Model sizes
    test_model_sizes()
    
    # Test 5: Performance
    benchmark_performance()
    
    # Summary
    print("\n" + "=" * 50)
    print("üìä TEST SUMMARY")
    print("=" * 50)
    
    print(f"MPS Basic: {'‚úÖ' if mps_basic else '‚ùå'}")
    print(f"Whisper MPS: {'‚úÖ' if whisper_mps else '‚ùå'}")
    print(f"Whisper CPU: {'‚úÖ' if whisper_cpu else '‚ùå'}")
    
    if whisper_mps:
        print("\nüéâ MPS fully compatible!")
        print("üí° S·ª≠ d·ª•ng MPS cho hi·ªáu su·∫•t t·ªët nh·∫•t")
    elif whisper_cpu:
        print("\n‚ö†Ô∏è  MPS c√≥ v·∫•n ƒë·ªÅ, s·ª≠ d·ª•ng CPU fallback")
        print("üí° Code s·∫Ω t·ª± ƒë·ªông fallback v·ªÅ CPU")
    else:
        print("\n‚ùå C·∫£ MPS v√† CPU ƒë·ªÅu c√≥ v·∫•n ƒë·ªÅ")
        print("üí° Ki·ªÉm tra c√†i ƒë·∫∑t PyTorch v√† Whisper")

if __name__ == "__main__":
    main()




